<!doctype html>
<html lang="ru">
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
</head>

<body style="font-family:system-ui;padding:12px">
  <h3>Tarot camera â†’ n8n</h3>

  <video id="v" autoplay playsinline
    style="width:100%;max-width:520px;border:1px solid #ccc;border-radius:12px"></video>

  <div style="margin:12px 0">
    <button id="start">Start</button>
    <button id="stop">Stop</button>

    <label style="margin-left:12px">Interval (ms):
      <input id="ms" type="number" value="1500" min="300" step="100" style="width:90px">
    </label>
  </div>

  <pre id="out" style="white-space:pre-wrap;background:#f6f6f6;padding:10px;border-radius:10px"></pre>

  <div style="margin:12px 0">
    <b>ðŸŽ§ Voice question:</b>
    <div id="q" style="white-space:pre-wrap;background:#eef;padding:10px;border-radius:10px;min-height:40px"></div>
    <div id="mic" style="opacity:.7;margin-top:6px"></div>
  </div>

<script>
const WEBHOOK_URL = "https://dinodi.app.n8n.cloud/webhook/06663b29-629e-409b-bf14-104d6d419d32";

let timer = null;
let stream = null;

// ===== VOICE â†’ QUESTION (wake phrase) =====
const WAKE_PHRASE = "ÐºÐ°Ñ€Ñ‚Ñ‹ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚Ðµ";
let captureMode = false;
let capturedText = "";
let silenceTimer = null;

// Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¼Ð¾Ð¶Ð½Ð¾ Ð±Ñ‹Ð»Ð¾ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ
let rec = null;
let manualStopSpeech = false;

const qEl = document.getElementById("q");
const micEl = document.getElementById("mic");

function setMicStatus(t){ micEl.textContent = t; }
function setQuestionPreview(t){ qEl.textContent = t || ""; }

function normalizeRu(s){
  return (s || "")
    .toLowerCase()
    .replace(/Ñ‘/g, "Ðµ")
    .replace(/[^\p{L}\p{N}\s]+/gu, " ")
    .replace(/\s+/g, " ")
    .trim();
}

const WAKE_NORM = normalizeRu(WAKE_PHRASE);

// â± Ñ„Ð¸ÐºÑÐ¸Ñ€ÑƒÐµÐ¼ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ÑÐ»Ðµ 3 ÑÐµÐºÑƒÐ½Ð´ Ñ‚Ð¸ÑˆÐ¸Ð½Ñ‹
function armSilenceCommit(){
  clearTimeout(silenceTimer);
  silenceTimer = setTimeout(async () => {
    const finalQ = capturedText.trim();

    if (captureMode && finalQ.length > 2) {
      captureMode = false;
      capturedText = "";

      setMicStatus("âœ… Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð·Ð°Ñ„Ð¸ÐºÑÐ¸Ñ€Ð¾Ð²Ð°Ð½. ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑŽâ€¦");
      setQuestionPreview(finalQ);

      await sendFrameWithQuestion(finalQ);

      setTimeout(() => setMicStatus("ðŸŽ§ Ð¡Ð»ÑƒÑˆÐ°ÑŽâ€¦ ÑÐºÐ°Ð¶Ð¸: Â«ÐºÐ°Ñ€Ñ‚Ñ‹ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÂ»"), 1200);
      return;
    }

    // ÐµÑÐ»Ð¸ Ñ‚Ð¸ÑˆÐ¸Ð½Ð° Ð½Ð°ÑÑ‚ÑƒÐ¿Ð¸Ð»Ð°, Ð½Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿ÑƒÑÑ‚Ð¾Ð¹ â€” ÑÐ±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ Ñ€ÐµÐ¶Ð¸Ð¼
    captureMode = false;
    capturedText = "";
    setQuestionPreview("");
    setMicStatus("ðŸŽ§ Ð¡Ð»ÑƒÑˆÐ°ÑŽâ€¦ ÑÐºÐ°Ð¶Ð¸: Â«ÐºÐ°Ñ€Ñ‚Ñ‹ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÂ»");
  }, 3000);
}

function startSpeech(){
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SR) {
    setMicStatus("âŒ SpeechRecognition Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ (Ð»ÑƒÑ‡ÑˆÐµ Chrome Ð½Ð° Ð½Ð¾ÑƒÑ‚Ð±ÑƒÐºÐµ).");
    return;
  }

  // ÐµÑÐ»Ð¸ ÑƒÐ¶Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð¾ â€” Ð½Ðµ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð²Ñ‚Ð¾Ñ€Ð¾Ð¹ Ñ€Ð°Ð·
  if (rec) return;

  manualStopSpeech = false;
  rec = new SR();
  rec.lang = "ru-RU";
  rec.continuous = true;
  rec.interimResults = true;

  rec.onstart = () => setMicStatus("ðŸŽ§ Ð¡Ð»ÑƒÑˆÐ°ÑŽâ€¦ ÑÐºÐ°Ð¶Ð¸: Â«ÐºÐ°Ñ€Ñ‚Ñ‹ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÐµÂ»");

  rec.onresult = (e) => {
    let finalText = "";
    for (let i = e.resultIndex; i < e.results.length; i++) {
      if (e.results[i].isFinal) finalText += e.results[i][0].transcript + " ";
    }
    if (!finalText.trim()) return;

    const norm = normalizeRu(finalText);

    // Ð¶Ð´Ñ‘Ð¼ ÐºÐ¾Ð´Ð¾Ð²ÑƒÑŽ Ñ„Ñ€Ð°Ð·Ñƒ
    if (!captureMode && norm.includes(WAKE_NORM)) {
      captureMode = true;

      // Ð²Ð¾Ð·ÑŒÐ¼Ñ‘Ð¼ Ñ…Ð²Ð¾ÑÑ‚ Ð¿Ð¾ÑÐ»Ðµ ÐºÐ¾Ð´Ð¾Ð²Ð¾Ð¹ Ñ„Ñ€Ð°Ð·Ñ‹ (ÐµÑÐ»Ð¸ ÑÑ€Ð°Ð·Ñƒ ÑÐºÐ°Ð·Ð°Ð»Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ)
      const idx = norm.indexOf(WAKE_NORM);
      const after = norm.slice(idx + WAKE_NORM.length).trim();
      capturedText = after ? after : "";

      setMicStatus("ðŸŽ™ï¸ Ð“Ð¾Ð²Ð¾Ñ€Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñâ€¦ (Ð·Ð°Ð¼Ð¾Ð»Ñ‡Ð¸ Ð½Ð° 3 ÑÐµÐºÑƒÐ½Ð´Ñ‹ â€” Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑŽ)");
      setQuestionPreview(capturedText);

      armSilenceCommit();
      return;
    }

    // ÐµÑÐ»Ð¸ Ð² Ñ€ÐµÐ¶Ð¸Ð¼Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ° â€” ÐºÐ¾Ð¿Ð¸Ð¼ Ñ‚ÐµÐºÑÑ‚
    if (captureMode) {
      capturedText += (capturedText ? " " : "") + finalText.trim();
      setQuestionPreview(capturedText);
      armSilenceCommit();
    }
  };

  rec.onend = () => {
    // Ð°Ð²Ñ‚Ð¾-Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐº, Ð½Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð¼Ñ‹ ÑÐ°Ð¼Ð¸ Ð½Ðµ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ð»Ð¸
    if (!manualStopSpeech) {
      setTimeout(() => { try { rec.start(); } catch(e) {} }, 400);
    }
  };

  rec.onerror = (e) => {
    setMicStatus("âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ: " + (e.error || "unknown"));
  };

  try { rec.start(); } catch(e) {}
}

function stopSpeech(){
  manualStopSpeech = true;
  try { if (rec) rec.stop(); } catch(e) {}
  rec = null;

  captureMode = false;
  capturedText = "";
  clearTimeout(silenceTimer);
  setQuestionPreview("");
  setMicStatus("");
}

// ===== CAMERA =====
async function startCam(){
  stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: { ideal: "environment" } },
    audio: false
  });
  document.getElementById('v').srcObject = stream;
}

function stopCam(){
  if (stream) stream.getTracks().forEach(t => t.stop());
  stream = null;
}

async function getFrameBlob(){
  const video = document.getElementById('v');
  if (!video.videoWidth || !video.videoHeight) return null;

  const canvas = document.createElement('canvas');
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  canvas.getContext('2d').drawImage(video, 0, 0);

  return await new Promise(r => canvas.toBlob(r, 'image/jpeg', 0.85));
}

// Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÐºÐ°Ð´Ñ€Ð° (ÑÑ‚Ñ€Ð¸Ð¼)
async function sendFrame(){
  const blob = await getFrameBlob();
  if (!blob) return;

  const fd = new FormData();
  fd.append('image', blob, 'frame.jpg');

  try{
    const res = await fetch(WEBHOOK_URL, { method: 'POST', body: fd });
    const text = await res.text();
    document.getElementById('out').textContent =
      `Sent frame: ${new Date().toLocaleTimeString()}\nResponse:\n${text}`;
  } catch(e){
    document.getElementById('out').textContent = `âŒ sendFrame error: ${String(e)}`;
  }
}

// Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° ÐºÐ°Ð´Ñ€Ð° + Ð²Ð¾Ð¿Ñ€Ð¾Ñ
async function sendFrameWithQuestion(question){
  const blob = await getFrameBlob();
  if (!blob) {
    document.getElementById('out').textContent = "âŒ ÐšÐ°Ð¼ÐµÑ€Ð° ÐµÑ‰Ñ‘ Ð½Ðµ Ð´Ð°Ð»Ð° ÐºÐ°Ð´Ñ€. ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸ 1â€“2 ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð¿Ð¾ÑÐ»Ðµ Start.";
    return;
  }

  const fd = new FormData();
  fd.append('image', blob, 'frame.jpg');
  fd.append('question', question);

  try{
    const res = await fetch(WEBHOOK_URL, { method: 'POST', body: fd });
    const text = await res.text();
    document.getElementById('out').textContent =
      `ðŸŽ™ Question sent: ${question}\nResponse:\n${text}`;
  } catch(e){
    document.getElementById('out').textContent = `âŒ sendFrameWithQuestion error: ${String(e)}`;
  }
}

// ===== UI buttons =====
document.getElementById('start').onclick = async () => {
  await startCam();

  // Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ Ð¿Ð¾ ÐºÐ»Ð¸ÐºÑƒ (Ñ‚Ð°Ðº Ð½Ð°Ð´ÐµÐ¶Ð½ÐµÐµ Ð´Ð»Ñ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð¾Ð²)
  startSpeech();

  const ms = Number(document.getElementById('ms').value || 1500);
  clearInterval(timer);
  timer = setInterval(sendFrame, ms);

  document.getElementById('out').textContent = "Streaming framesâ€¦";
};

document.getElementById('stop').onclick = () => {
  clearInterval(timer);
  stopCam();
  stopSpeech();
  document.getElementById('out').textContent = "Stopped.";
};
</script>

</body>
</html>
